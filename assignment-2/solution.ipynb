{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3979bd3-8495-45d7-a1f5-74e74d9d3878",
   "metadata": {},
   "source": [
    "# Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc634f26-e1fc-4138-92c7-1320ef88e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from joblib import Parallel, delayed\n",
    "from PIL import Image\n",
    "from skimage import transform\n",
    "from skimage.color import rgb2hed, rgba2rgb\n",
    "from skimage.io import imread\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f01734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/experiment_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3b46c-091d-43b3-9d06-4168b61c6329",
   "metadata": {},
   "source": [
    "# Utility functions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666c4db",
   "metadata": {},
   "source": [
    "Define some utility functions for working with images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753bc87-a3fa-4316-bf6e-43100db34331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_id: str) -> np.array:\n",
    "    \"\"\"Reads an image from the dataset\n",
    "\n",
    "    Args:\n",
    "        image_id (str): The id of the image to be read\n",
    "\n",
    "    Returns:\n",
    "        np.array: The image as a numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    image_folder = Path(\"data/patches_256\")\n",
    "\n",
    "    image_path = image_folder / f\"{image_id}.png\"\n",
    "\n",
    "    rgb_image = imread(image_path)\n",
    "\n",
    "    # if the image has an alpha channel, remove it\n",
    "    if rgb_image.shape[-1] == 4:\n",
    "        rgb_image = rgba2rgb(rgb_image)\n",
    "\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ccdc51-e2d8-4320-8cc1-ae77fccc418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rgb_to_hed(input_rgb_image: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Converts an RGB image to the HED color space.\n",
    "\n",
    "    Parameters:\n",
    "        input_rgb_image (np.array): The input RGB image.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The image converted to the HED color space.\n",
    "    \"\"\"\n",
    "    hed_image = rgb2hed(input_rgb_image)\n",
    "    return hed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f6bf1-f093-48b5-9b7b-21860bd37ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_intensity_avg(input_image: np.array, channel: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the average intensity for a specific channel in an RGB or HED image.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (np.array): The input image (RGB or HED).\n",
    "        channel (int): The channel index for which to calculate the average intensity.\n",
    "\n",
    "    Returns:\n",
    "        float: The average intensity for the specified channel.\n",
    "    \"\"\"\n",
    "    return input_image[:, :, channel].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f92ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_intensity_std(input_image: np.array, channel: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the standard deviation of the intensity for a specific channel in an RGB or HED image.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (np.array): The input image (RGB or HED).\n",
    "        channel (int): The channel index for which to calculate the standard deviation of the intensity.\n",
    "\n",
    "    Returns:\n",
    "        float: The standard deviation of the intensity for the specified channel.\n",
    "    \"\"\"\n",
    "    return input_image[:, :, channel].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775192a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_h_intensity(image_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the average H intensity of an image.\n",
    "\n",
    "    Parameters:\n",
    "        image_id (str): The ID of the image.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the image ID and the average H intensity.\n",
    "    \"\"\"\n",
    "    rgb_image = read_image(image_id)\n",
    "    hed_image = convert_rgb_to_hed(rgb_image)\n",
    "    avg_h_intensity = calculate_intensity_avg(hed_image, 0)\n",
    "    return {\n",
    "        \"image_id\": image_id,\n",
    "        \"avg_h_intensity\": avg_h_intensity,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loads protein expression data from a CSV file and splits it into training and testing datasets.\n",
    "\n",
    "    Returns:\n",
    "        training_data (pandas.DataFrame): The training dataset containing specimens A1, B1, and D1.\n",
    "        testing_data (pandas.DataFrame): The testing dataset containing specimen C1.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        \"https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs909/protein_expression_data.csv\"\n",
    "    )\n",
    "\n",
    "    # create specimen id field\n",
    "    df[\"specimen_id\"] = df.VisSpot.apply(lambda x: x.split(\"-\")[2])\n",
    "\n",
    "    # create image id field\n",
    "    df[\"image_id\"] = df.VisSpot.apply(lambda x: x.split(\"-\")[2]) + \"_\" + df.id\n",
    "\n",
    "    df = df.set_index(\"image_id\").sort_index()\n",
    "\n",
    "    # use specimens A1, B1 and D1 for training\n",
    "    training_data = df.loc[df[\"specimen_id\"].isin([\"A1\", \"B1\", \"D1\"])]\n",
    "\n",
    "    # use specimen C1 for testing\n",
    "    testing_data = df.loc[df[\"specimen_id\"].isin([\"C1\"])]\n",
    "\n",
    "    return training_data, testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d4feee-fe35-4e2f-a645-2016dc327593",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67a3f4",
   "metadata": {},
   "source": [
    "Load the proteint expression data after splitting it into training and testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde263ed-d1e2-44a2-acec-be5ea0acd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd9aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples:\", len(training_data))\n",
    "print(\"Number of testing samples:\", len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data = train_test_split(\n",
    "    training_data, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4cb988",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples:\", len(training_data))\n",
    "print(\"Number of validation samples:\", len(validation_data))\n",
    "print(\"Number of testing samples:\", len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf96963",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rgb_images_list = []\n",
    "training_hed_images_list = []\n",
    "\n",
    "\n",
    "def process_image(image_id):\n",
    "    rgb_image = read_image(image_id)\n",
    "    rgb_image_resized = transform.resize(rgb_image, (64, 64), anti_aliasing=True)\n",
    "    hed_image = convert_rgb_to_hed(rgb_image_resized)\n",
    "\n",
    "    return rgb_image_resized, hed_image\n",
    "\n",
    "\n",
    "training_images_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(process_image)(image_id) for image_id in training_data.index\n",
    ")\n",
    "\n",
    "testing_images_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(process_image)(image_id) for image_id in testing_data.index\n",
    ")\n",
    "\n",
    "training_rgb_images_list = [result[0] for result in training_images_list]\n",
    "training_hed_images_list = [result[1] for result in training_images_list]\n",
    "\n",
    "testing_rgb_images_list = [result[0] for result in testing_images_list]\n",
    "testing_hed_images_list = [result[1] for result in testing_images_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8902109",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rgb_images_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6360612",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_hed_images_list[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde55c9-b8a0-4222-a6ea-0a6c00906314",
   "metadata": {},
   "source": [
    "# Question No. 1: (Data Analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52714c1a",
   "metadata": {},
   "source": [
    "For the following questions, we will use only the `training_data`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712ad53-91b4-4599-a3ea-cc0a866bb3e0",
   "metadata": {},
   "source": [
    "## Counting Examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a7aa6-a359-4782-a815-00ad637089e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    training_data.groupby(\"specimen_id\", as_index=False)\n",
    "    .agg(n_sample=(\"id\", \"count\"))\n",
    "    .sort_values(\"n_sample\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a11daf-7d93-4d81-89b3-8aeefbb8ac99",
   "metadata": {},
   "source": [
    "## Protein Expression Histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(data=training_data, x=\"NESTIN\", col=\"specimen_id\", hue=\"specimen_id\")\n",
    "\n",
    "ax.set_titles(\"Protein expression in specimen NESTIN\")\n",
    "ax.set_xlabels(\"Protein expression\")\n",
    "ax.set_ylabels(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238ecfd-5caf-4858-bd17-e4bc04e69c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(data=training_data, x=\"cMYC\", col=\"specimen_id\", hue=\"specimen_id\")\n",
    "\n",
    "ax.set_titles(\"Protein expression in specimen cMYC\")\n",
    "ax.set_xlabels(\"Protein expression\")\n",
    "ax.set_ylabels(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27364f9d-7139-46a5-9076-f1aebc1247c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(data=training_data, x=\"MET\", col=\"specimen_id\", hue=\"specimen_id\")\n",
    "\n",
    "ax.set_titles(\"Protein expression in specimen MET\")\n",
    "ax.set_xlabels(\"Protein expression\")\n",
    "ax.set_ylabels(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519c0bf",
   "metadata": {},
   "source": [
    "From the above plots, we notice the following:\n",
    "\n",
    "1. Different protients have different ranges. `NESTIN` has values in the range `[-7, 1]`, `cMYC` has values in the range `[-10.5, 3.2]`, and `MET` has values in the range `[-10.7, 1.58]`\n",
    "\n",
    "2. The majority of the different protient values across different specimens are centered around 0, with fewer values spread around the extreme.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec311e42-1f84-4bf1-a285-ba7560aa1f25",
   "metadata": {},
   "source": [
    "## Image Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e387e30-aa31-47bc-b303-d848a98cead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "random_image_ids = np.random.choice(training_data.index, size=10)\n",
    "\n",
    "for image_id in random_image_ids:\n",
    "    rgb_image = read_image(image_id)\n",
    "\n",
    "    hed_image = convert_rgb_to_hed(rgb_image)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    ax[0].imshow(rgb_image)\n",
    "    ax[0].set_title(\"RGB Image\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    ax[1].imshow(hed_image[:, :, 0], cmap=\"gray\")\n",
    "    ax[1].set_title(\"H Channel\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa5676-4b8c-4d08-9c1c-04c6c4c4c07c",
   "metadata": {},
   "source": [
    "## H-channel Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(calculate_avg_h_intensity)(image_id) for image_id in training_data.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0513f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_df = pd.DataFrame(avg_h_intensity_list).set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd478ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_df = avg_h_intensity_df.join(training_data[[\"NESTIN\", \"specimen_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    data=avg_h_intensity_df,\n",
    "    x=\"avg_h_intensity\",\n",
    "    y=\"NESTIN\",\n",
    "    hue=\"specimen_id\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Average H intensity vs NESTIN expression\")\n",
    "ax.set_xlabel(\"Average H intensity\")\n",
    "ax.set_ylabel(\"NESTIN expression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2da5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = avg_h_intensity_df[\"avg_h_intensity\"].corr(avg_h_intensity_df[\"NESTIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ed00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The correlation between average H intensity and NESTIN expression is {correlation:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee15134",
   "metadata": {},
   "source": [
    "From the scatter plot and the correlation value we can see that there is a positive relation between the average intensity value of the `H` channel and the expression levels of `NESTIN`.\n",
    "\n",
    "However, this correlation is weak and won't capture the true relation of the target variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0053f17",
   "metadata": {},
   "source": [
    "## Performance Metrics for Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b633c0",
   "metadata": {},
   "source": [
    "# Question No. 2: (Feature Extraction and Classical Regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9986ea9-d173-4e90-9eb3-587e2d164982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_channel_stats(image_id: str):\n",
    "    \"\"\"\n",
    "    Calculate the intensity statistics for each channel of an image.\n",
    "\n",
    "    Args:\n",
    "        image_id (str): The ID of the image.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the image ID and the calculated intensity statistics for each channel.\n",
    "            - \"image_id\": The ID of the image.\n",
    "            - \"h_intensity_avg\": The average intensity of the H channel in the HED color space.\n",
    "            - \"h_intensity_std\": The standard deviation of the intensity of the H channel in the HED color space.\n",
    "            - \"r_intensity_avg\": The average intensity of the R channel in the RGB color space.\n",
    "            - \"r_intensity_std\": The standard deviation of the intensity of the R channel in the RGB color space.\n",
    "            - \"g_intensity_avg\": The average intensity of the G channel in the RGB color space.\n",
    "            - \"g_intensity_std\": The standard deviation of the intensity of the G channel in the RGB color space.\n",
    "            - \"b_intensity_avg\": The average intensity of the B channel in the RGB color space.\n",
    "            - \"b_intensity_std\": The standard deviation of the intensity of the B channel in the RGB color space.\n",
    "    \"\"\"\n",
    "    rgb_image = read_image(image_id)\n",
    "    hed_image = convert_rgb_to_hed(rgb_image)\n",
    "\n",
    "    h_intensity_avg = calculate_intensity_avg(hed_image, 0)\n",
    "    h_intensity_std = calculate_intensity_std(hed_image, 0)\n",
    "\n",
    "    r_intensity_avg = calculate_intensity_avg(rgb_image, 0)\n",
    "    r_intensity_std = calculate_intensity_std(rgb_image, 0)\n",
    "\n",
    "    g_intensity_avg = calculate_intensity_avg(rgb_image, 1)\n",
    "    g_intensity_std = calculate_intensity_std(rgb_image, 1)\n",
    "\n",
    "    b_intensity_avg = calculate_intensity_avg(rgb_image, 2)\n",
    "    b_intensity_std = calculate_intensity_std(rgb_image, 2)\n",
    "\n",
    "    return {\n",
    "        \"image_id\": image_id,\n",
    "        \"h_intensity_avg\": h_intensity_avg,\n",
    "        \"h_intensity_std\": h_intensity_std,\n",
    "        \"r_intensity_avg\": r_intensity_avg,\n",
    "        \"r_intensity_std\": r_intensity_std,\n",
    "        \"g_intensity_avg\": g_intensity_avg,\n",
    "        \"g_intensity_std\": g_intensity_std,\n",
    "        \"b_intensity_avg\": b_intensity_avg,\n",
    "        \"b_intensity_std\": b_intensity_std,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210701eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(calculate_image_channel_stats)(image_id) for image_id in training_data.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add2a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_df = pd.DataFrame(image_channels_stats_list).set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_df = image_channels_stats_df.join(\n",
    "    training_data[[\"NESTIN\", \"specimen_id\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c76b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ceb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb_images_list = []\n",
    "# hed_images_list = []\n",
    "\n",
    "# for image_id in training_data.index:\n",
    "#     rgb_image = read_image(image_id)\n",
    "#     rgb_image_resized = transform.resize(rgb_image, (64, 64), anti_aliasing=True)\n",
    "#     hed_image = convert_rgb_to_hed(rgb_image_resized)\n",
    "\n",
    "#     rgb_images_list.append(rgb_image_resized)\n",
    "#     hed_images_list.append(hed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd836b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_rgb_images_list = []\n",
    "# test_hed_images_list = []\n",
    "\n",
    "# for image_id in testing_data.index:\n",
    "#     rgb_image = read_image(image_id)\n",
    "#     rgb_image_resized = transform.resize(rgb_image, (64, 64), anti_aliasing=True)\n",
    "#     hed_image = convert_rgb_to_hed(rgb_image_resized)\n",
    "\n",
    "#     test_rgb_images_list.append(rgb_image_resized)\n",
    "#     test_hed_images_list.append(hed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c67ad",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f72d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_hed_images_list[0].shape, len(training_hed_images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hed_train = np.stack([hed_image[:, :, 0].flatten() for hed_image in training_hed_images_list], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c8f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hed_test = np.stack([hed_image[:, :, 0].flatten() for hed_image in testing_hed_images_list], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b939be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_hed_train.shape}\")\n",
    "print(f\"X_test shape: {X_hed_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddf7426",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(svd_solver=\"randomized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06beb8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the PCA model on the training data\n",
    "pca.fit(X_hed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of components that explain 95% of the variance\n",
    "n_components = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1\n",
    "print(f\"Number of components explaining 95% of variance: {n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a7043",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hed_train_pca = pca.transform(X_hed_train)\n",
    "X_hed_test_pca = pca.transform(X_hed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hed_train_reduced = X_hed_train_pca[:, :n_components]\n",
    "X_hed_test_reduced = X_hed_test_pca[:, :n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5b5403",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train_reduced shape:\", X_hed_train_reduced.shape)\n",
    "print(\"X_test_reduced shape:\", X_hed_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0c1a61",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd096b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_model.fit(X_hed_train_reduced, training_data[\"NESTIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b6e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVR_model.predict(X_hed_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3534f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_mean_squared_error(testing_data[\"NESTIN\"], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad3176",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(testing_data[\"NESTIN\"], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02659626",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=testing_data[\"NESTIN\"], y=y_pred, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939c73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dff9780",
   "metadata": {},
   "source": [
    "# Question No. 3 (Using Convolutional Neural Networks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # first convolutional layer\n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # second convolutional layer\n",
    "        self.conv_layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(32 * 17 * 17, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer_1(x)\n",
    "        out = self.conv_layer_2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161269b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of parameters in the model\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters in the model: {n_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "training_image_ids = training_data.index.to_numpy()\n",
    "training_labels = training_data[\"NESTIN\"].to_numpy()\n",
    "\n",
    "# validation data\n",
    "validation_image_ids = validation_data.index.to_numpy()\n",
    "validation_labels = validation_data[\"NESTIN\"].to_numpy()\n",
    "\n",
    "# testing data\n",
    "testing_image_ids = testing_data.index.to_numpy()\n",
    "testing_labels = testing_data[\"NESTIN\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b182aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBToHEDTransform:\n",
    "    def __call__(self, pic):\n",
    "        \"\"\"\n",
    "        Convert a PIL Image or numpy.ndarray from RGB to HED color space.\n",
    "\n",
    "        Parameters:\n",
    "            pic (PIL Image or numpy.ndarray): Image to be converted.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Converted image.\n",
    "        \"\"\"\n",
    "        # Convert PIL Image to numpy array\n",
    "        if isinstance(pic, Image.Image):\n",
    "            img_array = np.array(pic)\n",
    "        elif isinstance(pic, np.ndarray):\n",
    "            img_array = pic\n",
    "        elif torch.is_tensor(pic):\n",
    "            img_array = pic.numpy()\n",
    "            img_array = img_array.swapaxes(0, 2)\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"img should be PIL Image or ndarray. Got {}\".format(type(pic))\n",
    "            )\n",
    "\n",
    "        # Convert RGB to HED. The output array from rgb2hed can have negative values,\n",
    "        # so it's important to scale and shift the values to bring them into a suitable range (e.g., 0 to 1) if necessary.\n",
    "        hed_img = rgb2hed(img_array)\n",
    "\n",
    "        # return the H channel\n",
    "        return F.to_tensor(hed_img[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_ids: np.array, labels: np.array, transform=None):\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # read the image\n",
    "        rgb_image = read_image(image_id)\n",
    "\n",
    "        # apply transformation\n",
    "        if self.transform:\n",
    "            transformed_image = self.transform(rgb_image)\n",
    "\n",
    "        return transformed_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((64, 64)),\n",
    "        RGBToHEDTransform(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a8a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CustomDataset(training_image_ids, training_labels, transformations)\n",
    "validation_dataset = CustomDataset(\n",
    "    validation_image_ids, validation_labels, transformations\n",
    ")\n",
    "testing_dataset = CustomDataset(testing_image_ids, testing_labels, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650059a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "test_dataloader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcdd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataloader: DataLoader,\n",
    "    model: ConvNet,\n",
    "    loss_fn: nn.MSELoss,\n",
    "    optimizer: torch.optim.SGD,\n",
    "    epoch: int,\n",
    "):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if batch % 5 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    avg_train_loss = train_loss / size\n",
    "    writer.add_scalar(\"Loss/Train\", avg_train_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602013e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            X = torch.tensor(X, dtype=torch.float32)\n",
    "            y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    avg_val_loss = test_loss / size\n",
    "    writer.add_scalar(\"Loss/Validation\", avg_val_loss, epoch)\n",
    "\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f94a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "\n",
    "    train(train_dataloader, model, loss_fn, optimizer, epoch=t + 1)\n",
    "    test(validation_dataloader, model, loss_fn, epoch=t + 1)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96050431",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        pred = model(X)\n",
    "\n",
    "        predictions.append(pred)\n",
    "\n",
    "        test_loss += loss_fn(pred, y).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.cat(predictions).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d81bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=testing_data[\"NESTIN\"], y=predictions.squeeze(), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45016483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
