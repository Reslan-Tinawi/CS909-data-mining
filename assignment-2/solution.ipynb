{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3979bd3-8495-45d7-a1f5-74e74d9d3878",
   "metadata": {},
   "source": [
    "# Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc634f26-e1fc-4138-92c7-1320ef88e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from joblib import Parallel, delayed\n",
    "from skimage.color import rgb2hed, rgba2rgb\n",
    "from skimage.io import imread\n",
    "from sklearn.decomposition import PCA\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f01734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3b46c-091d-43b3-9d06-4168b61c6329",
   "metadata": {},
   "source": [
    "# Utility functions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666c4db",
   "metadata": {},
   "source": [
    "Define some utility functions for working with images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753bc87-a3fa-4316-bf6e-43100db34331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_id: str) -> np.array:\n",
    "    \"\"\"Reads an image from the dataset\n",
    "\n",
    "    Args:\n",
    "        image_id (str): The id of the image to be read\n",
    "\n",
    "    Returns:\n",
    "        np.array: The image as a numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    image_folder = Path(\"data/patches_256\")\n",
    "\n",
    "    image_path = image_folder / f\"{image_id}.png\"\n",
    "\n",
    "    rgb_image = imread(image_path)\n",
    "\n",
    "    # if the image has an alpha channel, remove it\n",
    "    if rgb_image.shape[-1] == 4:\n",
    "        rgb_image = rgba2rgb(rgb_image)\n",
    "\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ccdc51-e2d8-4320-8cc1-ae77fccc418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rgb_to_hed(input_rgb_image: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Converts an RGB image to the HED color space.\n",
    "\n",
    "    Parameters:\n",
    "        input_rgb_image (np.array): The input RGB image.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The image converted to the HED color space.\n",
    "    \"\"\"\n",
    "    hed_image = rgb2hed(input_rgb_image)\n",
    "    return hed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f6bf1-f093-48b5-9b7b-21860bd37ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_intensity_avg(input_image: np.array, channel: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the average intensity for a specific channel in an RGB or HED image.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (np.array): The input image (RGB or HED).\n",
    "        channel (int): The channel index for which to calculate the average intensity.\n",
    "\n",
    "    Returns:\n",
    "        float: The average intensity for the specified channel.\n",
    "    \"\"\"\n",
    "    return input_image[:, :, channel].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f92ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_intensity_std(input_image: np.array, channel: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the standard deviation of the intensity for a specific channel in an RGB or HED image.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (np.array): The input image (RGB or HED).\n",
    "        channel (int): The channel index for which to calculate the standard deviation of the intensity.\n",
    "\n",
    "    Returns:\n",
    "        float: The standard deviation of the intensity for the specified channel.\n",
    "    \"\"\"\n",
    "    return input_image[:, :, channel].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775192a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_h_intensity(image_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the average H intensity of an image.\n",
    "\n",
    "    Parameters:\n",
    "        image_id (str): The ID of the image.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the image ID and the average H intensity.\n",
    "    \"\"\"\n",
    "    rgb_image = read_image(image_id)\n",
    "    hed_image = convert_rgb_to_hed(rgb_image)\n",
    "    avg_h_intensity = calculate_intensity_avg(hed_image, 0)\n",
    "    return {\n",
    "        \"image_id\": image_id,\n",
    "        \"avg_h_intensity\": avg_h_intensity,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loads protein expression data from a CSV file and splits it into training and testing datasets.\n",
    "\n",
    "    Returns:\n",
    "        training_data (pandas.DataFrame): The training dataset containing specimens A1, B1, and D1.\n",
    "        testing_data (pandas.DataFrame): The testing dataset containing specimen C1.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        \"https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs909/protein_expression_data.csv\"\n",
    "    )\n",
    "\n",
    "    # create specimen id field\n",
    "    df[\"specimen_id\"] = df.VisSpot.apply(lambda x: x.split(\"-\")[2])\n",
    "\n",
    "    # create image id field\n",
    "    df[\"image_id\"] = df.VisSpot.apply(lambda x: x.split(\"-\")[2]) + \"_\" + df.id\n",
    "\n",
    "    df = df.set_index(\"image_id\").sort_index()\n",
    "\n",
    "    # use specimens A1, B1 and D1 for training\n",
    "    training_data = df.loc[df[\"specimen_id\"].isin([\"A1\", \"B1\", \"D1\"])]\n",
    "\n",
    "    # use specimen C1 for testing\n",
    "    testing_data = df.loc[df[\"specimen_id\"].isin([\"C1\"])]\n",
    "\n",
    "    return training_data, testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d4feee-fe35-4e2f-a645-2016dc327593",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67a3f4",
   "metadata": {},
   "source": [
    "Load the proteint expression data after splitting it into training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde263ed-d1e2-44a2-acec-be5ea0acd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd9aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples:\", len(training_data))\n",
    "print(\"Number of testing samples:\", len(testing_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde55c9-b8a0-4222-a6ea-0a6c00906314",
   "metadata": {},
   "source": [
    "# Question No. 1: (Data Analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52714c1a",
   "metadata": {},
   "source": [
    "For the following questions, we will use only the `training_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712ad53-91b4-4599-a3ea-cc0a866bb3e0",
   "metadata": {},
   "source": [
    "## Counting Examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a7aa6-a359-4782-a815-00ad637089e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    training_data.groupby(\"specimen_id\", as_index=False)\n",
    "    .agg(n_sample=(\"id\", \"count\"))\n",
    "    .sort_values(\"n_sample\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a11daf-7d93-4d81-89b3-8aeefbb8ac99",
   "metadata": {},
   "source": [
    "## Protein Expression Histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(data=training_data, x=\"NESTIN\", col=\"specimen_id\", hue=\"specimen_id\")\n",
    "\n",
    "ax.set_titles(\"Protein expression in specimen NESTIN\")\n",
    "ax.set_xlabels(\"Protein expression\")\n",
    "ax.set_ylabels(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238ecfd-5caf-4858-bd17-e4bc04e69c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(data=training_data, x=\"cMYC\", col=\"specimen_id\", hue=\"specimen_id\")\n",
    "\n",
    "ax.set_titles(\"Protein expression in specimen cMYC\")\n",
    "ax.set_xlabels(\"Protein expression\")\n",
    "ax.set_ylabels(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27364f9d-7139-46a5-9076-f1aebc1247c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(data=training_data, x=\"MET\", col=\"specimen_id\", hue=\"specimen_id\")\n",
    "\n",
    "ax.set_titles(\"Protein expression in specimen MET\")\n",
    "ax.set_xlabels(\"Protein expression\")\n",
    "ax.set_ylabels(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519c0bf",
   "metadata": {},
   "source": [
    "From the above plots, we notice the following:\n",
    "\n",
    "1. Different protients have different ranges. `NESTIN` has values in the range `[-7, 1]`, `cMYC` has values in the range `[-10.5, 3.2]`, and `MET` has values in the range `[-10.7, 1.58]`\n",
    "\n",
    "2. The majority of the different protient values across different specimens are centered around 0, with fewer values spread around the extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec311e42-1f84-4bf1-a285-ba7560aa1f25",
   "metadata": {},
   "source": [
    "## Image Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e387e30-aa31-47bc-b303-d848a98cead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "random_image_ids = np.random.choice(training_data.index, size=10)\n",
    "\n",
    "for image_id in random_image_ids:\n",
    "    rgb_image = read_image(image_id)\n",
    "\n",
    "    hed_image = convert_rgb_to_hed(rgb_image)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    ax[0].imshow(rgb_image)\n",
    "    ax[0].set_title(\"RGB Image\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    ax[1].imshow(hed_image[:, :, 0], cmap=\"gray\")\n",
    "    ax[1].set_title(\"H Channel\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa5676-4b8c-4d08-9c1c-04c6c4c4c07c",
   "metadata": {},
   "source": [
    "## H-channel Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(calculate_avg_h_intensity)(image_id) for image_id in training_data.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0513f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_df = pd.DataFrame(avg_h_intensity_list).set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd478ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_df = avg_h_intensity_df.join(training_data[[\"NESTIN\", \"specimen_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    data=avg_h_intensity_df, x=\"avg_h_intensity\", y=\"NESTIN\", hue=\"specimen_id\", alpha=0.2,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Average H intensity vs NESTIN expression\")\n",
    "ax.set_xlabel(\"Average H intensity\")\n",
    "ax.set_ylabel(\"NESTIN expression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2da5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = avg_h_intensity_df[\"avg_h_intensity\"].corr(avg_h_intensity_df[\"NESTIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ed00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The correlation between average H intensity and NESTIN expression is {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee15134",
   "metadata": {},
   "source": [
    "From the scatter plot and the correlation value we can see that there is a positive relation between the average intensity value of the `H` channel and the expression levels of `NESTIN`.\n",
    "\n",
    "However, this correlation is weak and won't capture the true relation of the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0053f17",
   "metadata": {},
   "source": [
    "## Performance Metrics for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b633c0",
   "metadata": {},
   "source": [
    "# Question No. 2: (Feature Extraction and Classical Regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9986ea9-d173-4e90-9eb3-587e2d164982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_channel_stats(image_id: str):\n",
    "    \"\"\"\n",
    "    Calculate the intensity statistics for each channel of an image.\n",
    "\n",
    "    Args:\n",
    "        image_id (str): The ID of the image.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the image ID and the calculated intensity statistics for each channel.\n",
    "            - \"image_id\": The ID of the image.\n",
    "            - \"h_intensity_avg\": The average intensity of the H channel in the HED color space.\n",
    "            - \"h_intensity_std\": The standard deviation of the intensity of the H channel in the HED color space.\n",
    "            - \"r_intensity_avg\": The average intensity of the R channel in the RGB color space.\n",
    "            - \"r_intensity_std\": The standard deviation of the intensity of the R channel in the RGB color space.\n",
    "            - \"g_intensity_avg\": The average intensity of the G channel in the RGB color space.\n",
    "            - \"g_intensity_std\": The standard deviation of the intensity of the G channel in the RGB color space.\n",
    "            - \"b_intensity_avg\": The average intensity of the B channel in the RGB color space.\n",
    "            - \"b_intensity_std\": The standard deviation of the intensity of the B channel in the RGB color space.\n",
    "    \"\"\"\n",
    "    rgb_image = read_image(image_id)\n",
    "    hed_image = convert_rgb_to_hed(rgb_image)\n",
    "\n",
    "    h_intensity_avg = calculate_intensity_avg(hed_image, 0)\n",
    "    h_intensity_std = calculate_intensity_std(hed_image, 0)\n",
    "\n",
    "    r_intensity_avg = calculate_intensity_avg(rgb_image, 0)\n",
    "    r_intensity_std = calculate_intensity_std(rgb_image, 0)\n",
    "\n",
    "    g_intensity_avg = calculate_intensity_avg(rgb_image, 1)\n",
    "    g_intensity_std = calculate_intensity_std(rgb_image, 1)\n",
    "\n",
    "    b_intensity_avg = calculate_intensity_avg(rgb_image, 2)\n",
    "    b_intensity_std = calculate_intensity_std(rgb_image, 2)\n",
    "\n",
    "    return {\n",
    "        \"image_id\": image_id,\n",
    "        \"h_intensity_avg\": h_intensity_avg,\n",
    "        \"h_intensity_std\": h_intensity_std,\n",
    "        \"r_intensity_avg\": r_intensity_avg,\n",
    "        \"r_intensity_std\": r_intensity_std,\n",
    "        \"g_intensity_avg\": g_intensity_avg,\n",
    "        \"g_intensity_std\": g_intensity_std,\n",
    "        \"b_intensity_avg\": b_intensity_avg,\n",
    "        \"b_intensity_std\": b_intensity_std,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210701eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(calculate_image_channel_stats)(image_id) for image_id in training_data.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add2a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_df = pd.DataFrame(image_channels_stats_list).set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_df = image_channels_stats_df.join(training_data[[\"NESTIN\", \"specimen_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c76b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca.fit_transform(training_images.reshape(-1, 256 * 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find the number of principal components that explain 95% of the variance\n",
    "# cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "# n_components = np.argmax(cumulative_variance > 0.95) + 1\n",
    "# print(f\"Number of components explaining 95% of the variance: {n_components}\")\n",
    "# # Number of components explaining 95% of the variance: 3433"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff9780",
   "metadata": {},
   "source": [
    "# Question No. 3 (Using Convolutional Neural Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # first convolutional layer\n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # second convolutional layer\n",
    "        self.conv_layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(32 * 33 * 33, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer_1(x)\n",
    "        out = self.conv_layer_2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161269b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of parameters in the model\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters in the model: {n_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_data: pd.DataFrame):\n",
    "        self.image_data = image_data\n",
    "        self.transform = transforms.Resize((128, 128))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_data.loc[idx, \"image_id\"]\n",
    "        label = self.image_data.loc[idx, \"NESTIN\"]\n",
    "\n",
    "        rgb_image = read_image(image_id)\n",
    "        hed_image = convert_rgb_to_hed(rgb_image)\n",
    "        h_channel = hed_image[:, :, 0]\n",
    "        # TODO:\n",
    "        #   Do we need to normalize the H channel?\n",
    "        h_channel_normalized = h_channel / 255.0\n",
    "\n",
    "        # h_channel_normalized = h_channel_normalized.reshape(1, 256, 256)\n",
    "        h_channel_normalized = np.expand_dims(h_channel_normalized, axis=0)\n",
    "\n",
    "        h_channel_normalized_tensor = torch.tensor(\n",
    "            h_channel_normalized, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        h_channel_normalized_tensor_resized = self.transform(\n",
    "            h_channel_normalized_tensor\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            h_channel_normalized_tensor_resized,\n",
    "            torch.tensor(label, dtype=torch.float32),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8002b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_meta = training_data.reset_index().loc[:, [\"image_id\", \"NESTIN\"]]\n",
    "testing_data_meta = testing_data.reset_index().loc[:, [\"image_id\", \"NESTIN\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb51173",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a8a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CustomDataset(training_data_meta)\n",
    "testing_dataset = CustomDataset(testing_data_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650059a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_dataset, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcdd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataloader: DataLoader,\n",
    "    model: ConvNet,\n",
    "    loss_fn: nn.MSELoss,\n",
    "    optimizer: torch.optim.SGD,\n",
    "    epoch: int,\n",
    "):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    avg_train_loss = train_loss / size\n",
    "    writer.add_scalar(\"Loss/Train\", avg_train_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602013e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    avg_val_loss = test_loss / size\n",
    "    writer.add_scalar(\"Loss/Test\", avg_val_loss, epoch)\n",
    "\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f94a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "\n",
    "    train(train_dataloader, model, loss_fn, optimizer, epoch=t + 1)\n",
    "    test(test_dataloader, model, loss_fn, epoch=t + 1)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b66553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
