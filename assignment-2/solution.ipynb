{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3979bd3-8495-45d7-a1f5-74e74d9d3878",
   "metadata": {},
   "source": [
    "# Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc634f26-e1fc-4138-92c7-1320ef88e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from joblib import Parallel, delayed\n",
    "from skimage import transform\n",
    "from skimage.color import rgb2hed, rgba2rgb\n",
    "from skimage.io import imread\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f01734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/experiment_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3b46c-091d-43b3-9d06-4168b61c6329",
   "metadata": {},
   "source": [
    "# Utility functions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666c4db",
   "metadata": {},
   "source": [
    "Define some utility functions for working with images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5753bc87-a3fa-4316-bf6e-43100db34331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_id: str) -> np.array:\n",
    "    \"\"\"Reads an image from the dataset\n",
    "\n",
    "    Args:\n",
    "        image_id (str): The id of the image to be read\n",
    "\n",
    "    Returns:\n",
    "        np.array: The image as a numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    image_folder = Path(\"data/patches_256\")\n",
    "\n",
    "    image_path = image_folder / f\"{image_id}.png\"\n",
    "\n",
    "    rgb_image = imread(image_path)\n",
    "\n",
    "    # if the image has an alpha channel, remove it\n",
    "    if rgb_image.shape[-1] == 4:\n",
    "        rgb_image = rgba2rgb(rgb_image)\n",
    "\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ccdc51-e2d8-4320-8cc1-ae77fccc418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rgb_to_hed(input_rgb_image: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Converts an RGB image to the HED color space.\n",
    "\n",
    "    Parameters:\n",
    "        input_rgb_image (np.array): The input RGB image.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The image converted to the HED color space.\n",
    "    \"\"\"\n",
    "    hed_image = rgb2hed(input_rgb_image)\n",
    "    return hed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e8f6bf1-f093-48b5-9b7b-21860bd37ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_intensity_avg(input_image: np.array, channel: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the average intensity for a specific channel in an RGB or HED image.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (np.array): The input image (RGB or HED).\n",
    "        channel (int): The channel index for which to calculate the average intensity.\n",
    "\n",
    "    Returns:\n",
    "        float: The average intensity for the specified channel.\n",
    "    \"\"\"\n",
    "    return input_image[:, :, channel].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f92ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_intensity_std(input_image: np.array, channel: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the standard deviation of the intensity for a specific channel in an RGB or HED image.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (np.array): The input image (RGB or HED).\n",
    "        channel (int): The channel index for which to calculate the standard deviation of the intensity.\n",
    "\n",
    "    Returns:\n",
    "        float: The standard deviation of the intensity for the specified channel.\n",
    "    \"\"\"\n",
    "    return input_image[:, :, channel].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "775192a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_h_intensity(image_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the average H intensity of an image.\n",
    "\n",
    "    Parameters:\n",
    "        image_id (str): The ID of the image.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the image ID and the average H intensity.\n",
    "    \"\"\"\n",
    "    rgb_image = read_image(image_id)\n",
    "    hed_image = convert_rgb_to_hed(rgb_image)\n",
    "    avg_h_intensity = calculate_intensity_avg(hed_image, 0)\n",
    "    return {\n",
    "        \"image_id\": image_id,\n",
    "        \"avg_h_intensity\": avg_h_intensity,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dbd356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loads protein expression data from a CSV file and splits it into training and testing datasets.\n",
    "\n",
    "    Returns:\n",
    "        training_data (pandas.DataFrame): The training dataset containing specimens A1, B1, and D1.\n",
    "        testing_data (pandas.DataFrame): The testing dataset containing specimen C1.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        \"https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs909/protein_expression_data.csv\"\n",
    "    )\n",
    "\n",
    "    # create specimen id field\n",
    "    df[\"specimen_id\"] = df.VisSpot.apply(lambda x: x.split(\"-\")[2])\n",
    "\n",
    "    # create image id field\n",
    "    df[\"image_id\"] = df.VisSpot.apply(lambda x: x.split(\"-\")[2]) + \"_\" + df.id\n",
    "\n",
    "    df = df.set_index(\"image_id\").sort_index()\n",
    "\n",
    "    # use specimens A1, B1 and D1 for training\n",
    "    training_data = df.loc[df[\"specimen_id\"].isin([\"A1\", \"B1\", \"D1\"])]\n",
    "\n",
    "    # use specimen C1 for testing\n",
    "    testing_data = df.loc[df[\"specimen_id\"].isin([\"C1\"])]\n",
    "\n",
    "    return training_data, testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d4feee-fe35-4e2f-a645-2016dc327593",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67a3f4",
   "metadata": {},
   "source": [
    "Load the proteint expression data after splitting it into training and testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde263ed-d1e2-44a2-acec-be5ea0acd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecd9aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 5792\n",
      "Number of testing samples: 4129\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples:\", len(training_data))\n",
    "print(\"Number of testing samples:\", len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdf96963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.18770958622494618s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1348719596862793s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 292 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 452 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 628 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 720 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 820 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 920 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1028 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1252 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1368 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1492 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1616 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1748 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1880 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2020 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2160 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2308 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2456 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2612 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2768 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2932 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3096 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3268 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3440 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3620 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3800 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3988 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4176 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4372 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4568 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4772 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4976 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 5188 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 5400 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 5620 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 5792 out of 5792 | elapsed:   19.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.06274557113647461s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.14143133163452148s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 292 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 436 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 512 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 596 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 680 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 772 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 864 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 964 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1064 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1172 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1280 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1396 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1512 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1760 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1892 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2164 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2304 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2452 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2600 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2756 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2912 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3076 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3240 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3412 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3584 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3764 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3944 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4129 out of 4129 | elapsed:   13.1s finished\n"
     ]
    }
   ],
   "source": [
    "training_rgb_images_list = []\n",
    "training_hed_images_list = []\n",
    "\n",
    "\n",
    "def process_image(image_id):\n",
    "    rgb_image = read_image(image_id)\n",
    "    rgb_image_resized = transform.resize(rgb_image, (64, 64), anti_aliasing=True)\n",
    "    hed_image = convert_rgb_to_hed(rgb_image_resized)\n",
    "\n",
    "    return rgb_image_resized, hed_image\n",
    "\n",
    "\n",
    "training_images_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(process_image)(image_id) for image_id in training_data.index\n",
    ")\n",
    "\n",
    "testing_images_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(process_image)(image_id) for image_id in testing_data.index\n",
    ")\n",
    "\n",
    "training_rgb_images_list = [result[0] for result in training_images_list]\n",
    "training_hed_images_list = [result[1] for result in training_images_list]\n",
    "\n",
    "testing_rgb_images_list = [result[0] for result in testing_images_list]\n",
    "testing_hed_images_list = [result[1] for result in testing_images_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8902109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c898f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85da6302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edde55c9-b8a0-4222-a6ea-0a6c00906314",
   "metadata": {},
   "source": [
    "# Question No. 1: (Data Analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52714c1a",
   "metadata": {},
   "source": [
    "For the following questions, we will use only the `training_data`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712ad53-91b4-4599-a3ea-cc0a866bb3e0",
   "metadata": {},
   "source": [
    "## Counting Examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a7aa6-a359-4782-a815-00ad637089e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    training_data.groupby(\"specimen_id\", as_index=False)\n",
    "    .agg(n_sample=(\"id\", \"count\"))\n",
    "    .sort_values(\"n_sample\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a11daf-7d93-4d81-89b3-8aeefbb8ac99",
   "metadata": {},
   "source": [
    "## Protein Expression Histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(data=training_data, x=\"NESTIN\", col=\"specimen_id\", hue=\"specimen_id\")\n",
    "\n",
    "ax.set_titles(\"Protein expression in specimen NESTIN\")\n",
    "ax.set_xlabels(\"Protein expression\")\n",
    "ax.set_ylabels(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238ecfd-5caf-4858-bd17-e4bc04e69c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(data=training_data, x=\"cMYC\", col=\"specimen_id\", hue=\"specimen_id\")\n",
    "\n",
    "ax.set_titles(\"Protein expression in specimen cMYC\")\n",
    "ax.set_xlabels(\"Protein expression\")\n",
    "ax.set_ylabels(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27364f9d-7139-46a5-9076-f1aebc1247c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(data=training_data, x=\"MET\", col=\"specimen_id\", hue=\"specimen_id\")\n",
    "\n",
    "ax.set_titles(\"Protein expression in specimen MET\")\n",
    "ax.set_xlabels(\"Protein expression\")\n",
    "ax.set_ylabels(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519c0bf",
   "metadata": {},
   "source": [
    "From the above plots, we notice the following:\n",
    "\n",
    "1. Different protients have different ranges. `NESTIN` has values in the range `[-7, 1]`, `cMYC` has values in the range `[-10.5, 3.2]`, and `MET` has values in the range `[-10.7, 1.58]`\n",
    "\n",
    "2. The majority of the different protient values across different specimens are centered around 0, with fewer values spread around the extreme.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec311e42-1f84-4bf1-a285-ba7560aa1f25",
   "metadata": {},
   "source": [
    "## Image Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e387e30-aa31-47bc-b303-d848a98cead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "random_image_ids = np.random.choice(training_data.index, size=10)\n",
    "\n",
    "for image_id in random_image_ids:\n",
    "    rgb_image = read_image(image_id)\n",
    "\n",
    "    hed_image = convert_rgb_to_hed(rgb_image)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    ax[0].imshow(rgb_image)\n",
    "    ax[0].set_title(\"RGB Image\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    ax[1].imshow(hed_image[:, :, 0], cmap=\"gray\")\n",
    "    ax[1].set_title(\"H Channel\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa5676-4b8c-4d08-9c1c-04c6c4c4c07c",
   "metadata": {},
   "source": [
    "## H-channel Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(calculate_avg_h_intensity)(image_id) for image_id in training_data.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0513f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_df = pd.DataFrame(avg_h_intensity_list).set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd478ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_df = avg_h_intensity_df.join(training_data[[\"NESTIN\", \"specimen_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_h_intensity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    data=avg_h_intensity_df,\n",
    "    x=\"avg_h_intensity\",\n",
    "    y=\"NESTIN\",\n",
    "    hue=\"specimen_id\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Average H intensity vs NESTIN expression\")\n",
    "ax.set_xlabel(\"Average H intensity\")\n",
    "ax.set_ylabel(\"NESTIN expression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2da5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = avg_h_intensity_df[\"avg_h_intensity\"].corr(avg_h_intensity_df[\"NESTIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ed00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The correlation between average H intensity and NESTIN expression is {correlation:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee15134",
   "metadata": {},
   "source": [
    "From the scatter plot and the correlation value we can see that there is a positive relation between the average intensity value of the `H` channel and the expression levels of `NESTIN`.\n",
    "\n",
    "However, this correlation is weak and won't capture the true relation of the target variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0053f17",
   "metadata": {},
   "source": [
    "## Performance Metrics for Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b633c0",
   "metadata": {},
   "source": [
    "# Question No. 2: (Feature Extraction and Classical Regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9986ea9-d173-4e90-9eb3-587e2d164982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_channel_stats(image_id: str):\n",
    "    \"\"\"\n",
    "    Calculate the intensity statistics for each channel of an image.\n",
    "\n",
    "    Args:\n",
    "        image_id (str): The ID of the image.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the image ID and the calculated intensity statistics for each channel.\n",
    "            - \"image_id\": The ID of the image.\n",
    "            - \"h_intensity_avg\": The average intensity of the H channel in the HED color space.\n",
    "            - \"h_intensity_std\": The standard deviation of the intensity of the H channel in the HED color space.\n",
    "            - \"r_intensity_avg\": The average intensity of the R channel in the RGB color space.\n",
    "            - \"r_intensity_std\": The standard deviation of the intensity of the R channel in the RGB color space.\n",
    "            - \"g_intensity_avg\": The average intensity of the G channel in the RGB color space.\n",
    "            - \"g_intensity_std\": The standard deviation of the intensity of the G channel in the RGB color space.\n",
    "            - \"b_intensity_avg\": The average intensity of the B channel in the RGB color space.\n",
    "            - \"b_intensity_std\": The standard deviation of the intensity of the B channel in the RGB color space.\n",
    "    \"\"\"\n",
    "    rgb_image = read_image(image_id)\n",
    "    hed_image = convert_rgb_to_hed(rgb_image)\n",
    "\n",
    "    h_intensity_avg = calculate_intensity_avg(hed_image, 0)\n",
    "    h_intensity_std = calculate_intensity_std(hed_image, 0)\n",
    "\n",
    "    r_intensity_avg = calculate_intensity_avg(rgb_image, 0)\n",
    "    r_intensity_std = calculate_intensity_std(rgb_image, 0)\n",
    "\n",
    "    g_intensity_avg = calculate_intensity_avg(rgb_image, 1)\n",
    "    g_intensity_std = calculate_intensity_std(rgb_image, 1)\n",
    "\n",
    "    b_intensity_avg = calculate_intensity_avg(rgb_image, 2)\n",
    "    b_intensity_std = calculate_intensity_std(rgb_image, 2)\n",
    "\n",
    "    return {\n",
    "        \"image_id\": image_id,\n",
    "        \"h_intensity_avg\": h_intensity_avg,\n",
    "        \"h_intensity_std\": h_intensity_std,\n",
    "        \"r_intensity_avg\": r_intensity_avg,\n",
    "        \"r_intensity_std\": r_intensity_std,\n",
    "        \"g_intensity_avg\": g_intensity_avg,\n",
    "        \"g_intensity_std\": g_intensity_std,\n",
    "        \"b_intensity_avg\": b_intensity_avg,\n",
    "        \"b_intensity_std\": b_intensity_std,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210701eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(calculate_image_channel_stats)(image_id) for image_id in training_data.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add2a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_df = pd.DataFrame(image_channels_stats_list).set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_df = image_channels_stats_df.join(\n",
    "    training_data[[\"NESTIN\", \"specimen_id\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c76b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ceb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_images_list = []\n",
    "hed_images_list = []\n",
    "\n",
    "for image_id in training_data.index:\n",
    "    rgb_image = read_image(image_id)\n",
    "    rgb_image_resized = transform.resize(rgb_image, (64, 64), anti_aliasing=True)\n",
    "    hed_image = convert_rgb_to_hed(rgb_image_resized)\n",
    "\n",
    "    rgb_images_list.append(rgb_image_resized)\n",
    "    hed_images_list.append(hed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd836b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rgb_images_list = []\n",
    "test_hed_images_list = []\n",
    "\n",
    "for image_id in testing_data.index:\n",
    "    rgb_image = read_image(image_id)\n",
    "    rgb_image_resized = transform.resize(rgb_image, (64, 64), anti_aliasing=True)\n",
    "    hed_image = convert_rgb_to_hed(rgb_image_resized)\n",
    "\n",
    "    test_rgb_images_list.append(rgb_image_resized)\n",
    "    test_hed_images_list.append(hed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24340fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hed_X = np.stack(\n",
    "    [hed_image[:, :, 0].flatten() for hed_image in hed_images_list], axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hed_X_test = np.stack(\n",
    "    [hed_image[:, :, 0].flatten() for hed_image in test_hed_images_list], axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hed_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aed4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "hed_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddf7426",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(svd_solver=\"randomized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06beb8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.fit_transform(hed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of components that explain 95% of the variance\n",
    "n_components = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1\n",
    "print(f\"Number of components: {n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a7043",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_top = X_pca[:, :n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00730c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd096b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_model.fit(X_pca_top, training_data[\"NESTIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda4ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_test = pca.transform(hed_X_test)[:, :n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b6e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVR_model.predict(X_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3534f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_mean_squared_error(testing_data[\"NESTIN\"], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad3176",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(testing_data[\"NESTIN\"], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02659626",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=testing_data[\"NESTIN\"], y=y_pred, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939c73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dff9780",
   "metadata": {},
   "source": [
    "# Question No. 3 (Using Convolutional Neural Networks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # first convolutional layer\n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # second convolutional layer\n",
    "        self.conv_layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(32 * 33 * 33, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer_1(x)\n",
    "        out = self.conv_layer_2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161269b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of parameters in the model\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters in the model: {n_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_data: pd.DataFrame):\n",
    "        self.image_data = image_data\n",
    "        self.transform = transforms.Resize((128, 128))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_data.loc[idx, \"image_id\"]\n",
    "        label = self.image_data.loc[idx, \"NESTIN\"]\n",
    "\n",
    "        rgb_image = read_image(image_id)\n",
    "        hed_image = convert_rgb_to_hed(rgb_image)\n",
    "        h_channel = hed_image[:, :, 0]\n",
    "\n",
    "        # h_channel_normalized = h_channel_normalized.reshape(1, 256, 256)\n",
    "        h_channel_normalized = np.expand_dims(h_channel_normalized, axis=0)\n",
    "\n",
    "        h_channel_normalized_tensor = torch.tensor(\n",
    "            h_channel_normalized, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        h_channel_normalized_tensor_resized = self.transform(\n",
    "            h_channel_normalized_tensor\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            h_channel_normalized_tensor_resized,\n",
    "            torch.tensor(label, dtype=torch.float32),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8002b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_meta = training_data.reset_index().loc[:, [\"image_id\", \"NESTIN\"]]\n",
    "testing_data_meta = testing_data.reset_index().loc[:, [\"image_id\", \"NESTIN\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb51173",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a8a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CustomDataset(training_data_meta)\n",
    "testing_dataset = CustomDataset(testing_data_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650059a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_dataset, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcdd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataloader: DataLoader,\n",
    "    model: ConvNet,\n",
    "    loss_fn: nn.MSELoss,\n",
    "    optimizer: torch.optim.SGD,\n",
    "    epoch: int,\n",
    "):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    avg_train_loss = train_loss / size\n",
    "    writer.add_scalar(\"Loss/Train\", avg_train_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602013e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    avg_val_loss = test_loss / size\n",
    "    writer.add_scalar(\"Loss/Test\", avg_val_loss, epoch)\n",
    "\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f94a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "\n",
    "    train(train_dataloader, model, loss_fn, optimizer, epoch=t + 1)\n",
    "    test(test_dataloader, model, loss_fn, epoch=t + 1)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b66553",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, labels) in enumerate(train_dataloader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(\n",
    "            \"Epoch [{}/{}], Step [{}/{}]\".format(1 + 1, 5, i + 1, len(train_dataloader))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c605f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
